{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# step0: dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import lxml.etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# step1: load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Download the dataset if it's not already there\n",
    "if not os.path.isfile('ted_en-20160408.zip'):\n",
    "    urllib.request.urlretrieve(\"https://wit3.fbk.eu/get.php?path=XML_releases/xml/ted_en-20160408.zip&filename=ted_en-20160408.zip\", filename=\"ted_en-20160408.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract both the texts and the labels from the xml file\n",
    "with zipfile.ZipFile('ted_en-20160408.zip', 'r') as z:\n",
    "    doc = lxml.etree.parse(z.open('ted_en-20160408.xml', 'r'))\n",
    "texts = doc.xpath('//content/text()')\n",
    "labels = doc.xpath('//head/keywords/text()')\n",
    "del doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2085 input texts, each a long string with text and punctuation.\n",
      "\n",
      "Here are two reasons companies fail: they only do more of the same, or they only do what's new.\n",
      "To m\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} input texts, each a long string with text and punctuation.\".format(len(texts)))\n",
    "print(\"\")\n",
    "print(texts[0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2085 labels in the form of keywords for each text.\n",
      "\n",
      "talks, business, creativity, curiosity, goal-setting, innovation, motivation, potential, success, work\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} labels in the form of keywords for each text.\".format(len(labels)))\n",
    "print(\"\")\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# step2: preprocess and tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2085\n",
      "['here', 'are', 'two', 'reasons', 'companies', 'fail', '<:_token>', 'they', 'only', 'do', 'more', 'of', 'the', 'same', '<,_token>', 'or', 'they', 'only', 'do', 'what', \"<'_token>\", 's', 'new', '<._token>', 'to', 'me', 'the', 'real', '<,_token>', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', '<:_token>', 'exploration', 'and', 'exploitation', '<._token>', 'both', 'are', 'necessary', '<,_token>', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing', '<._token>', 'consider', 'facit', '<._token>', 'i', \"<'_token>\", 'm', 'actually', 'old', 'enough', 'to', 'remember', 'them', '<._token>', 'facit', 'was', 'a', 'fantastic', 'company', '<._token>', 'they', 'were', 'born', 'deep', 'in', 'the', 'swedish', 'forest', '<,_token>', 'and', 'they', 'made', 'the', 'best', 'mechanical', 'calculators', 'in', 'the', 'world']\n"
     ]
    }
   ],
   "source": [
    "# preprocess the texts: lowercase, replace punctuation with tokens, tokenize into words (split on whitespace)\n",
    "#lowercase\n",
    "input_texts = [input_text.lower() for input_text in texts]\n",
    "#replace punctuation with punctuation tokens\n",
    "input_texts = [re.sub(r'([^a-z0-9\\s])', r' <\\1_token> ', input_text) for input_text in input_texts]\n",
    "#tokenize into words\n",
    "input_texts = [input_text.split() for input_text in input_texts]\n",
    "print(len(input_texts))\n",
    "print(input_texts[0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.00000000e+00   8.10500000e+02   1.61500000e+03   2.41950000e+03\n",
      "   3.22400000e+03   4.02850000e+03   4.83300000e+03   5.63750000e+03\n",
      "   6.44200000e+03   7.24650000e+03   8.05100000e+03]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Container object of 10 artists>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS1LnDHpJ6pxBL0mdM+glqXP/B0aua25s12ANAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8b4c413780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#histogram over input lengths\n",
    "Y_plot, X_plot = np.histogram([len(text) for text in input_texts], bins=10)\n",
    "print(X_plot)\n",
    "X_plot = np.arange(10)\n",
    "plt.bar(X_plot, +Y_plot, facecolor='#9999ff', edgecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are now only 2037 inputs left.\n"
     ]
    }
   ],
   "source": [
    "#remove all inputs that have less than 500 tokens in them\n",
    "inputs = zip(input_texts, labels)\n",
    "inputs = [text_and_labels for text_and_labels in inputs if len(text_and_labels[0]) > 500]\n",
    "print(\"There are now only {} inputs left.\".format(len(inputs)))\n",
    "input_texts, labels = zip(*inputs)\n",
    "input_texts, labels = list(input_texts), list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5353320 tokens in the dataset.\n",
      "There are 18428 tokens that appear only once.\n",
      "There are 18528 unique tokens to remove.\n",
      "There are now only 2012408 tokens in the dataset.\n"
     ]
    }
   ],
   "source": [
    "#get list of all words, and feed them into a Counter\n",
    "all_words = [word for input_text in input_texts for word in input_text]\n",
    "print(\"There are {} tokens in the dataset.\".format(len(all_words)))\n",
    "all_words_counter = Counter(all_words)\n",
    "\n",
    "#remove some noise, take away the 100 most common and all words that only appear once\n",
    "most_common_50 = [word for word, count in all_words_counter.most_common(100)]\n",
    "only_once = [word for word, count in all_words_counter.most_common() if count == 1]\n",
    "print(\"There are {} tokens that appear only once.\".format(len(only_once)))\n",
    "\n",
    "to_remove = set(only_once + most_common_50)\n",
    "print(\"There are {} unique tokens to remove.\".format(len(to_remove)))\n",
    "\n",
    "input_texts = [[word for word in input_text if word not in to_remove] for input_text in input_texts]\n",
    "\n",
    "new_all_words = [word for input_text in input_texts for word in input_text]\n",
    "print(\"There are now only {} tokens in the dataset.\".format(len(new_all_words)))\n",
    "\n",
    "#input_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 3, 5, 0, 0, 0, 0, 5]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess the labels: search for occurences of the keywords \"technology\", \"entertainment\" or \"design\" and build labels\n",
    "label_lookup = ['ooo', 'Too', 'oEo', 'ooD', 'TEo', 'ToD', 'oED', 'TED']\n",
    "for i in range(len(labels)):\n",
    "    ted_labels = ['o', 'o', 'o']\n",
    "    keyword_list = labels[i].split(', ')\n",
    "    if 'technology' in keyword_list:\n",
    "        ted_labels[0] = 'T'\n",
    "    if 'entertainment' in keyword_list:\n",
    "        ted_labels[1] = 'E'\n",
    "    if 'design' in keyword_list:\n",
    "        ted_labels[2] = 'D'\n",
    "    labels[i] = ''.join(ted_labels)\n",
    "    labels[i] = label_lookup.index(labels[i])\n",
    "len(labels)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# transform labels to one-hot\n",
    "labels_one_hot = np.zeros((len(labels), 8), dtype=int)            \n",
    "labels_one_hot[range(len(labels)), labels] = 1\n",
    "print(labels_one_hot[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mended', 'scott', 'analyzes', 'negligible', 'titillate', 'egan', 'skewed', 'collaborative', 'yo', 'trouser']\n",
      "36278\n",
      "36278\n",
      "[23671, 26313, 24371, 4147, 5524, 10293, 5524, 8643, 6031, 6031, 19774, 34453, 35035, 33545, 32118, 13759, 23671, 19335, 11769, 8408, 32962, 22091, 12183, 9610, 30199, 21966, 9080, 27460, 34211, 3345, 30967, 27460, 1385, 24827, 15380, 30077, 14724, 35266, 30330, 4290, 6854, 13579, 17178, 15853, 6905, 27460, 16360, 17029, 15547, 11638, 28544, 10230, 19657, 10293, 10933, 20058, 28481, 27719, 13873, 20628, 20628, 1648, 27460, 10312, 1302, 27460, 19130, 9607, 1620, 12386, 16360, 13579, 13172, 15853, 16545, 27168, 13579, 27460, 6905, 12183, 9610, 8408, 11769, 9372, 7330, 12183, 4107, 18360, 17706, 18039, 4353, 22076, 18899, 24827, 3121, 9907, 31905, 24827, 1690, 23127]\n"
     ]
    }
   ],
   "source": [
    "# creating the unique vocabulary lookup\n",
    "vocab_list = list(set([word for input_text in input_texts for word in input_text]))\n",
    "word_to_index = {}\n",
    "index_to_word = {}\n",
    "for i, word in enumerate(vocab_list, 1):\n",
    "    word_to_index[word] = i\n",
    "    index_to_word[i] = word\n",
    "input_indices_list = []\n",
    "for input_text in input_texts:\n",
    "    input_indices_list.append([word_to_index[word] for word in input_text])\n",
    "#del vocab_list\n",
    "#del input_texts\n",
    "print(vocab_list[:10])\n",
    "print(len(vocab_list))\n",
    "print(len(word_to_index))\n",
    "print(input_indices_list[0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#load glove word vectors\n",
    "glove = KeyedVectors.load_word2vec_format('glove.6B.50d.w2vformat.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35111/36278 words found in glove.\n"
     ]
    }
   ],
   "source": [
    "#creating embeddings, checking for each word in the input texts whether it is part of \n",
    "#the glove corpus, if yes intialize that row in the embeddings with the glove value, if\n",
    "#not initialize it uniformly between [-1.0, 1.0]\n",
    "voc_len = len(word_to_index)\n",
    "count = 0\n",
    "embeddings = np.random.uniform(-.3, .3, size=(voc_len+1, 50))\n",
    "for word, index in word_to_index.items():\n",
    "    if word in glove.vocab:\n",
    "        count += 1\n",
    "        embeddings[index] = glove[word]\n",
    "print(\"{}/{} words found in glove.\".format(count, voc_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2037, 500)\n"
     ]
    }
   ],
   "source": [
    "# truncate every input text to a fixed length for now, taking only the first x tokens, zero pad if smaller\n",
    "seq_length = 500\n",
    "inputs_truncated = np.zeros((len(input_indices_list), seq_length), dtype=int)\n",
    "for i, input_indices in enumerate(input_indices_list):\n",
    "    if len(input_indices) >= seq_length:\n",
    "        inputs_truncated[i, :seq_length] = np.array(input_indices)[:seq_length]\n",
    "    else:\n",
    "        inputs_truncated[i] = np.array(input_indices + ([0] * (seq_length-len(input_indices))))\n",
    "print(inputs_truncated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1630, 203, 204)\n"
     ]
    }
   ],
   "source": [
    "#keep the class label distribution intact\n",
    "inputs_combined = list(zip(inputs_truncated, labels_one_hot))\n",
    "inputs_train, inputs_test, inputs_cv = [], [], []\n",
    "for n in range(len(label_lookup)):\n",
    "    inputs_of_curr_class = [inpu for inpu in inputs_combined if np.argmax(inpu[1]) == n]\n",
    "    l = len(inputs_of_curr_class)\n",
    "    split1 = round(0.8*l)\n",
    "    split2 = round(0.9*l)\n",
    "    inputs_train.extend(inputs_of_curr_class[:split1])\n",
    "    inputs_cv.extend(inputs_of_curr_class[split1:split2])\n",
    "    inputs_test.extend(inputs_of_curr_class[split2:])\n",
    "\n",
    "shuffle(inputs_train)\n",
    "shuffle(inputs_cv)\n",
    "shuffle(inputs_test)\n",
    "print((len(inputs_train), len(inputs_test), len(inputs_cv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#now after shuffling we can unzip them again\n",
    "train_x, train_y = list(zip(*inputs_train))\n",
    "train_x, train_y = np.array([np.array(x) for x in train_x]), np.array(train_y)\n",
    "test_x, test_y = list(zip(*inputs_test))\n",
    "test_x, test_y = np.array([np.array(x) for x in test_x]), np.array(test_y)\n",
    "cv_x, cv_y = list(zip(*inputs_cv))\n",
    "cv_x, cv_y = np.array([np.array(x) for x in cv_x]), np.array(cv_y)\n",
    "#train_y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niZQCQEQkUv8PLdel9Zs+XYQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8ad4728898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting a histogram over the label distribution in the entire dataset\n",
    "#as you can see 'ooo' is basically ~50% of the dataset, so an accuracy score\n",
    "#of 50% could be reached by simply learning to predict 'ooo' all the time (not good)\n",
    "Y_plot = np.histogram(labels, bins=8)[0]\n",
    "X_plot = np.arange(8)\n",
    "plt.bar(X_plot, +Y_plot, facecolor='#9999ff', edgecolor='white')\n",
    "for x,y in zip(X_plot,Y_plot):\n",
    "    plt.text(x, y+0.05, label_lookup[x], ha='center', va= 'bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# step3: building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 200\n",
    "learning_rate = 0.001\n",
    "show_every_n_batches = 10\n",
    "\n",
    "# size of hidden RNN state\n",
    "rnn_size = 100\n",
    "# length of input sequences\n",
    "seq_length = 500\n",
    "step_length = 10\n",
    "num_steps = int(seq_length/step_length)\n",
    "print(num_steps)\n",
    "# length of word embeddings\n",
    "embed_length = 50\n",
    "#number of classes to classify between\n",
    "n_classes = 8\n",
    "#number of unique words in the vocabulary\n",
    "n_words = len(vocab_list)\n",
    "#number of RNN layers\n",
    "rnn_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create the graph object\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    inputs_ph = tf.placeholder(tf.int32, [None, seq_length], name='inputs')\n",
    "    labels_ph = tf.placeholder(tf.int32, [None, n_classes], name='labels')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 500, 50)\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    #embedding = tf.Variable(tf.random_uniform((n_words, embed_length), -1, 1))\n",
    "    embedding = tf.Variable(embeddings, \"L\")\n",
    "    embed = tf.nn.embedding_lookup(embedding, inputs_ph)\n",
    "    embed = tf.cast(embed, dtype=tf.float32)\n",
    "    print(embed.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 500, 100)\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    # LSTM forward and backward cells\n",
    "    lstm_fw = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "    \n",
    "    # Add dropout to the cell\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm_fw, output_keep_prob=keep_prob)\n",
    "    \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop] * rnn_layers)\n",
    "    \n",
    "    # Getting an initial state of all zeros\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    #print(out)\n",
    "    # Computing the RNN outputs, truncated backprop style\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell, tf.cast(embed, dtype=tf.float32), initial_state=initial_state)\n",
    "    print(outputs.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 8)\n",
      "()\n",
      "(200,)\n",
      "(200, 8)\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    #out\n",
    "    #logits = tf.contrib.layers.fully_connected(inputs=outputs[:, -1], num_outputs=n_classes, activation_fn=None)\n",
    "    logits = tf.contrib.layers.fully_connected(inputs=tf.reduce_mean(outputs, axis=1), num_outputs=n_classes, activation_fn=None)\n",
    "    print(logits.get_shape())\n",
    "    \n",
    "    #loss\n",
    "    #l2_cost = tf.nn.l2_loss(W1) + tf.nn.l2_loss(b1)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_ph))# + (0.01*l2_cost)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "            \n",
    "    #acc\n",
    "    #predictions = tf.nn.softmax(logits)\n",
    "    predictions = logits #no need to softmax here because we really only want the argmax\n",
    "    correct_predictions = tf.equal(tf.argmax(predictions, axis=1), tf.argmax(labels_ph, axis=1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "    \n",
    "    print(accuracy.get_shape())\n",
    "    print(correct_predictions.get_shape())\n",
    "    print(predictions.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_batches(x, y, batch_size=50):\n",
    "    n_batches = len(x)//batch_size\n",
    "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "    for i in range(0, len(x), batch_size):\n",
    "        yield x[i:i+batch_size], y[i:i+batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# step4: training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1630, 8)\n",
      "(1630, 8)\n",
      "Epoch: 1/20 Iteration: 10 Train loss: 1.437\n",
      "Train acc: 0.510, Val acc: 0.550\n",
      "(1630, 8)\n",
      "Epoch: 2/20 Iteration: 20 Train loss: 1.329\n",
      "Train acc: 0.539, Val acc: 0.550\n",
      "(1630, 8)\n",
      "Epoch: 3/20 Iteration: 30 Train loss: 1.419\n",
      "Train acc: 0.538, Val acc: 0.550\n",
      "(1630, 8)\n",
      "Epoch: 4/20 Iteration: 40 Train loss: 1.141\n",
      "Train acc: 0.561, Val acc: 0.560\n",
      "(1630, 8)\n",
      "(1630, 8)\n",
      "Epoch: 6/20 Iteration: 50 Train loss: 1.098\n",
      "Train acc: 0.560, Val acc: 0.575\n",
      "(1630, 8)\n",
      "Epoch: 7/20 Iteration: 60 Train loss: 1.140\n",
      "Train acc: 0.565, Val acc: 0.570\n",
      "(1630, 8)\n",
      "Epoch: 8/20 Iteration: 70 Train loss: 1.183\n",
      "Train acc: 0.595, Val acc: 0.575\n",
      "(1630, 8)\n",
      "Epoch: 9/20 Iteration: 80 Train loss: 0.893\n",
      "Train acc: 0.627, Val acc: 0.615\n",
      "(1630, 8)\n",
      "(1630, 8)\n",
      "Epoch: 11/20 Iteration: 90 Train loss: 0.912\n",
      "Train acc: 0.632, Val acc: 0.620\n",
      "(1630, 8)\n",
      "Epoch: 12/20 Iteration: 100 Train loss: 0.964\n",
      "Train acc: 0.650, Val acc: 0.635\n",
      "(1630, 8)\n",
      "Epoch: 13/20 Iteration: 110 Train loss: 0.988\n",
      "Train acc: 0.659, Val acc: 0.610\n",
      "(1630, 8)\n",
      "Epoch: 14/20 Iteration: 120 Train loss: 0.730\n",
      "Train acc: 0.697, Val acc: 0.640\n",
      "(1630, 8)\n",
      "(1630, 8)\n",
      "Epoch: 16/20 Iteration: 130 Train loss: 0.765\n",
      "Train acc: 0.700, Val acc: 0.600\n",
      "(1630, 8)\n",
      "Epoch: 17/20 Iteration: 140 Train loss: 0.829\n",
      "Train acc: 0.714, Val acc: 0.630\n",
      "(1630, 8)\n",
      "Epoch: 18/20 Iteration: 150 Train loss: 0.906\n",
      "Train acc: 0.723, Val acc: 0.655\n",
      "(1630, 8)\n",
      "Epoch: 19/20 Iteration: 160 Train loss: 0.701\n",
      "Train acc: 0.729, Val acc: 0.625\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    for e in range(num_epochs):\n",
    "        state = sess.run(initial_state)\n",
    "        print(train_y.shape)\n",
    "        train_acc = []\n",
    "        for i, (x, y) in enumerate(get_batches(train_x, train_y, batch_size), 1):\n",
    "            feed = {inputs_ph: x,\n",
    "                    labels_ph: y,\n",
    "                    keep_prob: 0.5,\n",
    "                    initial_state: state}\n",
    "            loss, train_batch_acc, state, _ = sess.run([cost, accuracy, final_state, optimizer], feed_dict=feed)\n",
    "            train_acc.append(train_batch_acc)\n",
    "            \n",
    "            if iteration%10==0:\n",
    "                print(\"Epoch: {}/{}\".format(e, num_epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Train loss: {:.3f}\".format(loss))\n",
    "\n",
    "            if iteration%10==0:\n",
    "                cv_acc = []\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                for x, y in get_batches(cv_x, cv_y, batch_size):\n",
    "                    feed = {inputs_ph: x,\n",
    "                            labels_ph: y,\n",
    "                            keep_prob: 1.0,\n",
    "                            initial_state: val_state}\n",
    "                    pred, batch_acc, val_state = sess.run([predictions, accuracy, final_state], feed_dict=feed)\n",
    "                    cv_acc.append(batch_acc)\n",
    "                    #print(np.argmax(pred, axis=1))\n",
    "                    #print(np.argmax(y, axis=1))\n",
    "                print(\"Train acc: {:.3f}, Val acc: {:.3f}\".format(np.mean(train_acc), np.mean(cv_acc)))\n",
    "            iteration +=1\n",
    "    saver.save(sess, \"checkpoints/rnn_text_classification.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# step5: testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8a811e80f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJBXu/wM5GSZllrjAmgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8a823434a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_acc = []\n",
    "test_preds_acc = []\n",
    "true_labels_acc = []\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints/'))\n",
    "    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "    for x, y in get_batches(test_x, test_y, batch_size):\n",
    "        feed = {inputs_ph: x,\n",
    "                labels_ph: y,\n",
    "                keep_prob: 1,\n",
    "                initial_state: test_state}\n",
    "        test_preds, batch_acc, test_state = sess.run([predictions, accuracy, final_state], feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "        test_preds_acc.extend(np.argmax(test_preds, axis=1))\n",
    "        true_labels_acc.extend(np.argmax(y, axis=1))\n",
    "        #print(np.argmax(test_preds, axis=1))\n",
    "        #print(np.argmax(y, axis=1))\n",
    "    print(\"Test accuracy: {:.3f}\".format(np.mean(test_acc)))\n",
    "\n",
    "bins = np.arange(9)\n",
    "plt.hist(np.array(test_preds_acc), bins, alpha=0.5, label='predictions')\n",
    "plt.hist(np.array(true_labels_acc), bins, alpha=0.5, label='truth')\n",
    "plt.legend(loc='upper right')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(input_texts[4][0:300])\n",
    "print(labels[4])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
